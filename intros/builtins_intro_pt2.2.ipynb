{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part the following modules will be covered:\n",
    "\n",
    "- file handling: `os json pickle pathlib`\n",
    "- containter datatypes: `collections`\n",
    "- iterators: `itertools`\n",
    "- enumerators: `enum`\n",
    "- regular expressions: `re`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.2. Standard library\n",
    "\n",
    "The task is the same: replace `...` (Ellipsis) symbols with suitable pieces of code. \n",
    "\n",
    "You can find all the files for this notebook in the `pt2.2_files` zip archive. Unzip it and place the folder in the same directory as the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES = 'pt2.2_files'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `os`\n",
    "\n",
    "You can use this module to access files and directories on your PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`os.path.join`\n",
    "\n",
    "This function enables you to join paths. This method is in all ways superior to concatenating path strings with `+` as it takes into account OS-specific symbols.\n",
    "\n",
    "Let's create a path to the `1.json` file located in `json_files/` subdirectory in `FILES` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_SUBDIR = 'json_files'; FILENAME = 'foijy.json'\n",
    "bad_way = FILES + '/' + JSON_SUBDIR + '/' + FILENAME\n",
    "good_way = os.path.join(FILES, JSON_SUBDIR, FILENAME)\n",
    "# note: there's even a better way to do this with pathlib\n",
    "\n",
    "print(bad_way, good_way, sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`os.listdir`\n",
    "\n",
    "Use this function to get a list of all files in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_json_files() -> list[str]:\n",
    "    '''\n",
    "    Return a list of all .json filenames from that `json_files/` directory.\n",
    "    '''\n",
    "    return [filename for filename in os.listdir(os.path.join(FILES, JSON_SUBDIR)) if filename.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "res = all_json_files()\n",
    "assert res, 'Empty list of filenames'\n",
    "assert all(el.endswith('.json') for el in res), 'Conststs non-json file formats'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pathlib`\n",
    "\n",
    "An even better way to deal with paths. This modules allows for storing them now as strings, but as the `Path` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the intuitive division operator (`/`) to create child paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES_PL = Path('pt2.2_files'); JSON_SUBDIR = Path('json_files'); FILENAME = Path('foijy.json')\n",
    "\n",
    "best_way = FILES_PL / JSON_SUBDIR / FILENAME\n",
    "print(best_way)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also get useful information about the file/folder at destination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('is directory (points to a folder):', best_way.is_dir())\n",
    "print('is file:', best_way.is_file())\n",
    "print('check if the file exists:', best_way.exists())\n",
    "print('file\\'s extension:', best_way.suffix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even open the file with the `.open` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with best_way.open() as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use these `Path` objects in same way as the string paths. However, they come with added functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the absolute path\n",
    "abs_path = best_way.absolute()\n",
    "print(abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the contents of a directory matching a given pattern\n",
    "json_folder = FILES_PL / JSON_SUBDIR\n",
    "print('all files:', list(json_folder.glob(pattern='*.*'))) \n",
    "print('json only:', list(json_folder.glob(pattern='*.json'))) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further reading: https://docs.python.org/3/library/pathlib.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `json`\n",
    "\n",
    "JSON format is widely used to serialize dictionary-like data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read that `1.json` json file and return it as a `dict` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_read_json() -> dict:\n",
    "    '''\n",
    "    Returns a dictionary generated from the contents of ./pt2.2_files/json_files/1.json.\n",
    "    '''\n",
    "    with open(os.path.join(FILES, JSON_SUBDIR, '1.json')) as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "res = simple_read_json()\n",
    "assert res['school_name'] == 'HSE'\n",
    "assert res['reg_code'][:4] == 'dbf3'\n",
    "assert len(res['grades']) == 26"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the tests pass?\n",
    "\n",
    "If yes, now use the `all_json_files` function to get all json filenames, open all of them one by one, create a summary in one `list` of `dict`s and save it to a file called `summary.json` to the `pt2.2_files/output/` directory.\n",
    "\n",
    "The summary dictionary should have the following format:\n",
    "\n",
    "```\n",
    "summary = [\n",
    "    {\n",
    "        'school_name': ...,\n",
    "        'reg_code_7': ...,\n",
    "        'average_grade': ...\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "That is, a list of dictionaries with the following keys: \n",
    "- `school_name`, \n",
    "- `reg_code_7` (first 7 charachters of the original `'reg_code'`)\n",
    "- `average_grade` (arithmetic mean of the original `'grades'` list rounded to 3 decimal digits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean # use this instead of sum(grades)/len(grades)\n",
    "\n",
    "def create_summary_object() -> list[dict[str, str | float]]:\n",
    "    '''\n",
    "    Create a summary object as described above\n",
    "    in a form of a list of dictionaries.\n",
    "\n",
    "    Hint 1: use `all_json_files` to access the filenames.\n",
    "    '''\n",
    "    json_files = all_json_files()\n",
    "    summary = []\n",
    "    for jf in json_files:\n",
    "        with open(os.path.join(FILES, JSON_SUBDIR, jf), 'r') as f:\n",
    "            raw_data = json.load(f)\n",
    "        summary.append(\n",
    "            {\n",
    "                'school_name': raw_data['school_name'],\n",
    "                'reg_code_7': raw_data['reg_code'][:7],\n",
    "                'average_grade': round(mean(raw_data['grades']), 3)\n",
    "            }\n",
    "        )\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "res = create_summary_object()\n",
    "assert isinstance(res, list), 'result must be a list object'\n",
    "assert isinstance(res[0], dict), 'each element must be a dict object'\n",
    "assert len(res) == 5\n",
    "assert {el['reg_code_7'] for el in res} == {'dbf3fd7', 'e5dcffe', 'c701f30', '51c670b', 'bfe3a1c'}, \\\n",
    "    'Something wrong with the reg_code_7 fields'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, save this object in the `summary.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_TO = os.path.join(FILES, 'output', 'summary.json')\n",
    "\n",
    "with open(SAVE_TO, 'w') as f:\n",
    "    json.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "assert os.path.exists(SAVE_TO), f'{SAVE_TO} file does not exist'\n",
    "with open(SAVE_TO) as f: assert res == json.load(f), 'Object saved and object created are not equal'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BONUS: reading json from urls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also read json data directly from a url address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "URL = 'https://global-warming.org/api/ocean-warming-api'\n",
    "response = urlopen(URL)\n",
    "\n",
    "data = json.loads(response.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n",
    "print(data['description'])\n",
    "print(f'in total: {len(data[\"result\"])} temperature measurements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_years_anomalies() -> tuple[list[int], list[float]]:\n",
    "    '''\n",
    "    Extract useful measurements from the `data` dictionary stored under the `'result'` key\n",
    "    as another dictionary.\n",
    "    Return a tuple of (list of years as ints, list of temperatures as floats)\n",
    "    '''\n",
    "    years = []; anomalies = []\n",
    "    for y, a in data['result'].items():\n",
    "        years.append(int(y))\n",
    "        anomalies.append(float(a))\n",
    "    return years, anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrs, anom = create_years_anomalies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "import math\n",
    "assert isinstance(yrs[0], int), 'Elements of yrs must be integers'\n",
    "assert isinstance(anom[0], float), 'Elements of anom must be floats'\n",
    "assert yrs == list(range(1880, 2023)), 'Incorrect list of years'\n",
    "assert math.isclose(sum(anom), 10.44), 'Something wrong with the anom elements'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If previous tests passed, run the second next cell to plot a graph of \"temperature anomaly by year\".\n",
    "\n",
    "Make sure that you have the `matplotlib` module installed by running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from statistics import mean\n",
    "\n",
    "# generating sliding average data\n",
    "anom_sliding = []\n",
    "win_size = 5\n",
    "for i in range(win_size, len(anom) - win_size):\n",
    "    anom_sliding.append(mean(anom[i-win_size:i+win_size]))\n",
    "\n",
    "# plt.plot(yrs, [0] * len(yrs))\n",
    "plt.plot(yrs, anom, ':.', label='data points')\n",
    "plt.plot(yrs[win_size:-win_size], anom_sliding, label='sliding average')\n",
    "plt.title('Temperature anomaly by year')\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('anomaly, degrees Celsius')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pickle`\n",
    "\n",
    "See the `pickle_pickle_pickle.py` skeleton."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `csv`\n",
    "\n",
    "CSV = comma separated values. It's a serialization method to store table-like objects.\n",
    "\n",
    "First line contains names of the columns (normally, separated by commas). Next lines contain data corresponding to those columns. Take a look at the `pt2.2_files/csv_files/example.csv` file to get a better picture of how the data is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "CSV_SUBDIR = 'csv_files'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read a json file using the `csv.DictReader`. This will make each row a dictionary with column names as keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(FILES, CSV_SUBDIR, 'example.csv')) as f:\n",
    "    csv_reader = csv.DictReader(f)\n",
    "    for row in csv_reader:\n",
    "        print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note_ that an empty value in the 4th row has been replaced with an empty string."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably won't need to use the `csv` module as is, because this format is supported by many side-packages (like `numpy`, `pandas`, etc.) where there exist separate functions designed to deal with `.csv` files.\n",
    "\n",
    "For example, there is how easy it is to read a matrix in `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy is a side-package; make sure that it is installed on your PC\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "MATRIX_FILEPATH = os.path.join(FILES, CSV_SUBDIR, 'matrix.csv')\n",
    "matr = np.loadtxt(MATRIX_FILEPATH, dtype=int, delimiter=',')\n",
    "print(matr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `enum`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `itertools`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def pairwise_products(a: list[int]) -> int:\n",
    "    #? remember this problem from pt1?\n",
    "    # now solve it using itertools.combinations\n",
    "    # note: this will be less efficient than the linear solution.\n",
    "    '''*\n",
    "    For a list of integers find the sum of all pairwise products.\n",
    "    It is guaranteed that len(a) >= 2.\n",
    "    Ex.: [2,5,4] -> 2*5 + 2*4 + 5*4 = 38\n",
    "    '''\n",
    "    import math\n",
    "    return sum(map(math.prod, combinations(a, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test pairwise_products\n",
    "assert pairwise_products([2,5,4]) == 38\n",
    "assert pairwise_products([1,2,3,4,5,6]) == 175\n",
    "assert pairwise_products([1,2,0]) == 2\n",
    "assert pairwise_products([5,3]) == 15"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `collections`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `re`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thevenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
